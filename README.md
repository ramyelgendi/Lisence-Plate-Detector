# License Plate Detector
## Introduction
### Problem Definition
License plate detection (LPD) is becoming one of the most growing areas of study in intelligent traffic systems. LPD provides automation for road tax collections, traffic signals defilement implementation, and monitoring unlike activities. There are many problems associated with current LPD systems such as motion blur, since all vehicles are moving at a high speed on highways, which makes it harder for CCTV cameras to get a clear shot and a clear angle for license detection. Also, there could be more than one car in a frame and this might interfere with license plate characters recognition which is why we must locate and isolate the plate first before moving to the next step which is extracting the characters from the plate. Also, as mentioned earlier, the captured images most of the time have low quality due to motion blur, and also due to the very low resolution of CCTV cameras. 
Motivation
In this project, we aim to improve upon existing deep neural networks techniques that are used for the detection of license plates and extraction of their characters. This system is intended to help the police and mostly for traffic police for doing their work efficiently and in very small amounts of time. We intend to use Convolutional Neural Networks for tackling this problem, and we will be trying different optimizers and loss functions to try and achieve the best possible accuracy.
### Literature Review
LPD is the core for all vehicle surveillance systems. There have been many solutions for detecting plates but each country has its own shape, color, standard font and style for their plates. (Parker & Federl, 1996). Most of the solutions are generally based on color information, special characters and symbols. We believe that these approaches are ineffective and limited, especially since colors and characters vary depending on the country.
One of the most used methods in binary imaging systems is the Connected Component Analysis technique (Kwaśnicka & Wawrzyniak, 2002). CCA scans previously linearized images then matches them pixel by pixel into connected components. This works fine when the size of texts/pixels of licenses is equal but for our case, we aim to use it for more than one country, so we want to account for different sizes which will mean having different pixel connectivity. 
Another known solution is Region Growing Algorithm (Van Heerden & Botha, 2010), which uses recursion, along with some dark areas which represent symbols of license plates. The limitations of the RGA algorithm is that it depends on priorly knowing the dimensions of the license plate, color, and font. Also, the background of the license plate should always be lighter than the plate text, which as mentioned is not the case for all of the english license plates. 
## Proposed Solution
Our proposed solution is to train a convolutional neural network capable of locating license plates on new images, then isolate this page and extract the characters from the plate. We aim to use the OpenCV library to draw the rectangle containing the license plate. Initially, we will normalize our dataset and transform them into a numpy array. Then, we will split the dataset into a training set, validation set, and testing test. 60% of the dataset will be for training, 20% will be for validation, and finally 20% for testing. Our convolutional neural network will have 6 layers, the first layer will be VGG16 that uses image net, and deals with the picture as an RBG. We chose this model because it achieves 92% of the top 5 tests of accuracy in imagenet which has over 14 million images belonging to 1000 classes (“Popular Networks for Computer Vision Tasks.”). Then, the next layer is to flatten the results, then followed by a series of dense layers with relu activations, and ending it with a sigmoid activation layer. Our optimizer will be Adam and for the loss function we will use mean squared error, because after trial and error these parameters are what achieved the highest accuracy. After that, we crop our images at the rectangle coordinates extracted in the previous part, then we apply a sharpening filter before passing them on to the next section. We will then use a pre-trained machine learning model imported from easyOCR library to detect english characters on the license plate and extract them.
This solution is better than the previous solutions that we mentioned in our literature review because we are following a deep neural network technique to automatically identify license plates with different sizes, images, and fonts through convolutional neural networking, a model that reaches accuracies in image processing more than its previous predecessors. 

## Experimental Results
Dataset: 433 images of cars showing their license plates from different countries at different angles, distance and lighting

The accuracy of the localization system is 89 percent. In most cases, it places a rectangle correctly over the license plate to be moved on to the OCR part of character detection. This is very competitive compared to other solutions, the highest of which are in the 70s or early 80s in terms of percentage accuracy.
The accuracy of our recognition system is 50 percent. This is very good compared to the fact that we ran the OCR on the output of our first CNN, which wasn't 100 percent accurate. Some of the cropped images sent to the OCR section had a fraction of the plate and some didn't have them at all. Also, some images were taken from very far away, so after getting cropped, they were so pixelated that a human wouldn't be able to recognize the characters.

## Dataset Link:
Kaggle: faridrizqis/anpr-easyocr

## Conclusion
In conclusion, we believe we reached very good results, which are also competitive compared to other existing solutions. It was very interesting to research what other people have reached in this field and was an overall very interesting project. Viewing a machine learning problem such as the one in study was very eye-opening, because it showed us how machine learning is truly integrated in every corner of our lives. Our future work would include making the system also work for other languages, or any languages, not just English. Also, we could apply it to moving pictures, or videos, not just still images.
## References
- Cheng,  Y.,  Lu,  J.,  &  Yahagi,  T.  (2004).  Car  license  plate  recognition  based  on  the  combination  of  principal components  analysis  and  radIal basis  function  networks. Proceedings Of 7Th International  Conference on Signal Processing,2, 1455-1458. IEEE. http://dx.doi.org/10.1109/icosp.2004.1441601
- Kwaśnicka, H., & Wawrzyniak, B. (2002). License plate localization and recognition in camera pictures. In 3rd Symposium on Methods of Artificial Intelligence (pp. 243-246).
- Moustafa, Akram & Jaradat, Mohammed-Issa. (2015). A New Approach for License Plate Detection and Localization: Between Reality and Applicability. International Business Research. 8. 13. 10.5539/ibr.v8n11p13. 
- Parker, J. R., & Federl, P. (1996).An approach to license plate recognition.Computer Science Technical Report,(1996-591-1. I).
- “Popular Networks for Computer Vision Tasks.” For Computer Vision Tasks, 23 Jan. 2019, https://neurohive.io/en/popular-networks/. 
- Van  Heerden,  R.  P.,  &  Botha,  E.  C.  (2010). Optimization  of  vehicle  license  plate  segmentation  and  symbol recognition. Department of Electrical, Electronic and Computer Engineering, University of Pretoria, South Africa.


